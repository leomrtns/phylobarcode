# Necessary databases

phylobarcode needs a set of genomes in FASTA format, a set of genomes in GFF3 format, and a GTDB metadata file to
include taxonomic annotation. 

The GTDB file is usually available at `https://data.gtdb.ecogenomic.org/releases/latest/bac120_metadata.tar.gz`. Notice
that although it's a single file, it is archived with `tar` (to store the file's actual name with release info, I assume). 
So you can do something like:
```
tar zxovf bac120_metadata_r207.tar.gz bac120_metadata_r207.tsv | xz -T 8 -7e > bac120_metadata_r207.tsv.xz
```

(please veryify the release number, `r207` in my case).

For reference FASTA sequences, we are using ReferenceSeeker, and the database can currently be downloaded from zenodo
(instructions in https://github.com/oschwengers/referenceseeker#databases). 
We are using the bacteria refseq (release 205) available at https://zenodo.org/record/4415843/files/bacteria-refseq.tar.gz


And for the GFF3 files with the gene annotation, we download all complete assemblies available through
`ncbi-genome-download`:
```bash
ncbi-genome-download --assembly-level complete --flat-output bacteria -F gff
```

phylobarcode will use the `seqid` from the GFF3 files (`ssu_query_id` etc. in the GTDB metadata file) to match between
the threee sources. This program (`phylobarcode merge_fasta_gff`) can be quite slow due to the GFF file reading step, so
you may want to play with subsets. 

## Comments from pilot(old) experiments 

Since we already have a fasta database (referenceseeker) we can cross with `transfer/outgoing/databases/referenceseeker/` to see which GFFs have an equivalent FASTA.
In the example below we chose 1k random files, but we can use all (currently 21k) files.
```bash
\ls GCF_* | cut -d "." -f 1 | grep -f referenceseeker.names > both_here_and_refseq.names
for i in `shuf both_here_and_refseq.names | head -n 1000`; do cp ${i}* small/; cp /home/nbi_transfer/outgoing/databases/referenceseeker/bacteria-refseq/${i}* small/; done
```

Notice that this is not needed for current versions of phylobarcode, it can do this subsampling on the fly (although slower!).

Alternatively one can use `ncbi-genome-download` again for the fasta, or https://github.com/lskatz/Kalamari. I'll
download the kalamari tables and restrict the blast database to them 
([commit 459a5d1644dee4f2a57252f1de7830ab8fd95a64](https://github.com/lskatz/Kalamari/commit/459a5d1644dee4f2a57252f1de7830ab8fd95a64)).
Notice that there are ~300 chromosomes and ~10k plasmids in the kalamari DB.


To map the fasta file to their contents, we create a table `<filename> <header>`:
```bash
for i in ../gff3/referenceseeker/GCF_*; do zcat $i | grep ">" | cut -c 2- | gawk -v var=$i '{print var,$0}' | perl -pe "s/.*?referenceseeker\///;" ; done > refseeker_headercontents.txt
```

Concatenate fasta files represented in kalamari:
```bash
cut -f 2 kalamari.tsv > kalamari_accession.txt # kalamari.tsv has concatenated `choromosone.tsv` and `plasmid.tsv`
for i in `grep -f kalamari_accession.txt refseeker_headercontents.txt | cut -d' ' -f 1 | sort | uniq`; do zcat ../gff3/referenceseeker/$i >> kalamari.fasta; done

# create blast DB 
makeblastdb -dbtype nucl -in kalamari.fasta -title "files from kalamari chrom and plasmids"
```
